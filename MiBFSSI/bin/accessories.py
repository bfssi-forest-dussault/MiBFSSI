import re
import shutil
import logging
import pandas as pd

from pathlib import Path
from dataclasses import dataclass
from subprocess import Popen, PIPE
from config import DEPENDENCIES


@dataclass
class Sample(object):
    def __lt__(self, other):
        """Allows for Sample objects to be sorted"""
        return self.sample_id < other.sample_id

    # Mandatory attributes
    sample_id: str
    r1: Path
    r2: Path
    outdir: Path

    # Optional attributes
    reference_genome: Path = None
    taxid: str = None
    taxname: str = None
    bamfile: Path = None
    mapping_stats: Path = None
    mapping_stats_df: pd.DataFrame = None
    assembly: Path = None


def get_sample_dictionary(directory: Path, forward_id: str, reverse_id: str) -> dict:
    """
    Chains several functions together to create a sample dictionary with unique/valid sample IDs as keys
    and paths to forward and reverse reads as values
    :param directory: Path to a directory containing .fastq.gz files
    :param forward_id: ID indicating forward read in filename (e.g. _R1)
    :param reverse_id: ID indicating reverse read in filename (e.g. _R2)
    :return: Validated sample dictionary with sample_ID:R1,R2 structure
    """
    fastq_file_list = retrieve_fastqgz(directory)
    sample_id_list = retrieve_unique_sampleids(fastq_file_list)
    sample_dictionary = populate_sample_dictionary(sample_id_list, fastq_file_list, forward_id, reverse_id)
    logging.info(f"Successfully paired {len(sample_dictionary)} samples")
    return sample_dictionary


def retrieve_fastqgz(directory: Path) -> [Path]:
    """
    :param directory: Path to folder containing output from MiSeq run
    :return: LIST of all .fastq.gz files in directory
    """
    fastq_file_list = list(directory.glob("*.f*q*"))
    return fastq_file_list


def retrieve_unique_sampleids(fastq_file_list: [Path]) -> list:
    """
    :param fastq_file_list: List of fastq.gz filepaths generated by retrieve_fastqgz()
    :return: List of valid OLC Sample IDs
    """
    # Iterate through all of the fastq files and grab the sampleID, append to list
    sample_id_list = list()
    for f in fastq_file_list:
        sample_id = f.name.split('_')[0]
        sample_id_list.append(sample_id)

    # Get unique sample IDs
    sample_id_list = list(set(sample_id_list))
    return sample_id_list


def prepare_nullarbor_sample_file(samples: [Sample], outdir: Path) -> Path:
    outfile = outdir / 'Nullarbor_SampleSheet.tab'

    # Create dataframe with relevant sample object metadata
    d = []
    for sample in samples:
        d.append({'SampleID': sample.sample_id, 'R1': sample.r1, 'R2': sample.r2})
    df = pd.DataFrame(d)

    # Reorder columns
    df = df[['SampleID', 'R1', 'R2']]

    # Export to .tab file
    df.to_csv(outfile, sep="\t", index=None, header=False)
    return outfile


def taxid_list_to_text(taxid_list: list, outdir: Path) -> Path:
    taxfile = Path(outdir) / "taxids.txt"
    with open(taxfile, mode="w") as outfile:
        for s in taxid_list:
            outfile.write(f"{s}\n")
    return taxfile


def populate_sample_dictionary(sample_id_list: list, fastq_file_list: [Path], forward_id: str,
                               reverse_id: str) -> dict:
    """
    :param sample_id_list: List of unique Sample IDs generated by retrieve_unique_sampleids()
    :param fastq_file_list: List of fastq.gz file paths generated by retrieve_fastqgz()
    :param forward_id: ID indicating forward read in filename (e.g. _R1)
    :param reverse_id: ID indicating reverse read in filename (e.g. _R2)
    :return: dictionary with each Sample ID as a key and the read pairs as values
    """
    # Find file pairs for each unique sample ID
    sample_dictionary = {}
    for sample_id in sample_id_list:
        read_pair = get_readpair(sample_id, fastq_file_list, forward_id, reverse_id)
        if read_pair is not None:
            sample_dictionary[sample_id] = read_pair
        else:
            pass
    return sample_dictionary


def run_subprocess(cmd: str):
    p = Popen(cmd, shell=True)
    p.wait()


def run_subprocess_stdout(cmd: str) -> tuple:
    p = Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)
    out, err = p.communicate()
    out = out.decode('utf-8')
    err = err.decode('utf-8')

    # Strip all ANSI escape characters
    ansi_escape = re.compile(r'\x1B\[[0-?]*[ -/]*[@-~]')
    err = ansi_escape.sub('', err)

    return out, err


def parse_genome_results(mapping_stats: Path, sample_id=None) -> pd.DataFrame:
    # Read in stats .txt file
    df = pd.read_csv(mapping_stats, delimiter="\t", index_col=None)

    # Rename columns from bbmap output
    column_names = [
        "Reference_genome", "Avg_fold", "Length(bp)", "Ref_GC",
        "Covered_percent", "Covered_bases", "Plus_reads", "Minus_reads",
        "Read_GC", "Median_fold", "Std_dev"
    ]
    df.columns = column_names

    # Add SampleID
    if sample_id is None:
        df["SampleID"] = mapping_stats.name.split(".")[0]
    else:
        df["SampleID"] = sample_id

    # Rearrange column headers
    column_names_sorted = [
        "SampleID", "Reference_genome", "Avg_fold", "Median_fold",
        "Std_dev", "Length(bp)", "Ref_GC", "Covered_percent",
        "Covered_bases", "Plus_reads", "Minus_reads", "Read_GC"
    ]
    df = df[column_names_sorted]
    return df


def combine_dataframes(dfs: list) -> pd.DataFrame:
    df = pd.concat(dfs)
    return df


def get_readpair(sample_id: str, fastq_file_list: [Path], forward_id: str, reverse_id: str) -> list:
    """
    :param sample_id: String of sample ID
    :param fastq_file_list: List of fastq.gz file paths generated by retrieve_fastqgz()
    :param forward_id: ID indicating forward read in filename (e.g. _R1)
    :param reverse_id: ID indicating reverse read in filename (e.g. _R2)
    :return: the absolute filepaths of R1 and R2 for a given sample ID
    """

    r1, r2 = None, None
    for f in fastq_file_list:
        if sample_id in f.name:
            if forward_id in f.name:
                r1 = f
            elif reverse_id in f.name:
                r2 = f
    if r1 is not None:
        return [r1, r2]
    else:
        logging.debug('Could not pair {}'.format(sample_id))


def parse_snippy(snippy_dir: Path) -> tuple:
    snippy_summary = list(snippy_dir.glob('*.tab'))[0]
    snippy_vcf = list(snippy_dir.glob('*.vcf'))[0]
    snippy_consensus = list(snippy_dir.glob('*.aligned.fa'))[0]
    snippy_bam = list(snippy_dir.glob('*.bam'))[0]
    return snippy_summary, snippy_vcf, snippy_consensus, snippy_bam


def dependency_check(dependency: str) -> bool:
    """
    Checks if a given program is present in the user's $PATH
    :param dependency: String of program name
    :return: True if program is in $PATH, False if not
    """
    check = shutil.which(dependency)
    if check is not None:
        return True
    else:
        return False


def check_dependencies():
    # Dependency check
    logging.info("Conducting dependency check...")
    dependency_dict = dict()
    for dependency in DEPENDENCIES:
        dependency_dict[dependency] = dependency_check(dependency)
    if False in dependency_dict.values():
        logging.error("ERROR: Cannot locate some dependencies in $PATH...")
        for key, value in dependency_dict.items():
            if not value:
                logging.error(f"Dependency missing: {key}")
        quit()
    else:
        for key, value in dependency_dict.items():
            logging.debug(f"Dependency {key}: {value}")
    logging.info("Dependencies OK")
